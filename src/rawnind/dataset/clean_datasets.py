"""
Clean dataset classes for raw image processing.

This module contains clean dataset classes for both Bayer and RGB image processing.
"""

import logging
import random

import torch
import tqdm

from rawnind.dependencies import pytorch_helpers as pt_helpers, load_yaml

from .base_dataset import CleanCleanImageDataset, RawDatasetOutput, TOY_DATASET_LEN
from .bayer_datasets import ProfiledRGBBayerImageDataset
from .rgb_datasets import ProfiledRGBProfiledRGBImageDataset


class CleanProfiledRGBCleanBayerImageCropsDataset(
    CleanCleanImageDataset, ProfiledRGBBayerImageDataset
):
    """
    Dataloader for pre-cropped unpaired images generated by tools/crop_dataset.py w/ metadata from tools/prep_image_dataset_extraraw.py.
    """

    def __init__(
        self,
        content_fpaths: list[str],
        num_crops: int,
        crop_size: int,
        toy_dataset: bool = False,
    ):
        super().__init__(num_crops=num_crops, crop_size=crop_size)
        self.num_crops = num_crops
        self._dataset = []  # (gt_fpath, src_fpath)
        for content_fpath in content_fpaths:
            logging.info(
                f"CleanProfiledRGBCleanBayerImageCropsDataset.__init__: loading {content_fpath}"
            )
            ds_content = load_yaml(content_fpath, error_on_404=True)
            for all_metadata in tqdm.tqdm(ds_content):
                if toy_dataset and len(self._dataset) >= TOY_DATASET_LEN:
                    break
                useful_metadata = {
                    "overexposure_lb": all_metadata["overexposure_lb"],
                    "rgb_xyz_matrix": torch.tensor(all_metadata["rgb_xyz_matrix"]),
                    "crops": all_metadata["crops"],
                }
                if not useful_metadata["crops"]:
                    logging.warning(
                        f"CleanProfiledRGBCleanBayerImageCropsDataset.__init__: image {all_metadata} has no useful crops; not adding to dataset."
                    )
                else:
                    self._dataset.append(useful_metadata)
        logging.info(f"initialized {type(self).__name__} with {len(self)} images.")
        if len(self) == 0:
            raise ValueError("Dataset is empty")

    def __getitem__(self, i: int) -> RawDatasetOutput:
        metadata = self._dataset[i]
        crop: dict[str, str] = random.choice(metadata["crops"])
        try:
            gt = pt_helpers.fpath_to_tensor(crop["gt_linrec2020_fpath"]).float()
            rgbg_img = pt_helpers.fpath_to_tensor(crop["gt_bayer_fpath"]).float()
        except ValueError as e:
            logging.error(e)
            return self.__getitem__(random.randrange(len(self)))
        mask = self.get_mask(rgbg_img, metadata)
        try:
            x_crops, y_crops, mask_crops = self.random_crops(gt, rgbg_img, mask)
        except AssertionError as e:
            logging.info(crop)
            raise AssertionError(f"{self} {e} with {crop=}")
        except RuntimeError as e:
            logging.error(e)
            logging.error(f"{gt.shape=}, {rgbg_img.shape=}, {mask.shape=}")
            raise RuntimeError(f"{self} {e} with {crop=}")
        except TypeError:
            logging.warning(
                f"{crop} does not contain sufficient valid pixels; removing from dataset"
            )
            self._dataset[i]["crops"].remove(crop)
            if len(self._dataset[i]["crops"]) == 0:
                logging.warning(
                    f"{self._dataset[i]} does not contain anymore valid crops. Removing whole image from dataset."
                )
                self._dataset.remove(self._dataset[i])
            return self.__getitem__(i)
        return {
            "x_crops": x_crops,
            "y_crops": y_crops,
            "mask_crops": mask_crops,
            "rgb_xyz_matrix": metadata["rgb_xyz_matrix"],
            "gain": 1.0,
        }

    def __len__(self) -> int:
        return len(self._dataset)


class CleanProfiledRGBCleanProfiledRGBImageCropsDataset(
    CleanCleanImageDataset, ProfiledRGBProfiledRGBImageDataset
):
    """
    Dataloader for pre-cropped unpaired images generated by tools/crop_dataset.py w/ metadata from tools/prep_image_dataset_extraraw.py.
    """

    def __init__(
        self,
        content_fpaths: list[str],
        num_crops: int,
        crop_size: int,
        toy_dataset: bool = False,
        arbitrary_proc_method: bool = False,
    ):
        super().__init__(num_crops=num_crops, crop_size=crop_size)
        self.arbitrary_proc_method = arbitrary_proc_method
        self.num_crops = num_crops
        self._dataset = []  # (gt_fpath, src_fpath)
        for content_fpath in content_fpaths:
            logging.info(
                f"CleanProfiledRGBCleanProfiledRGBImageCropsDataset.__init__: loading {content_fpath}"
            )
            ds_content = utilities.load_yaml(content_fpath, error_on_404=True)
            for all_metadata in tqdm.tqdm(ds_content):
                if toy_dataset and len(self._dataset) >= TOY_DATASET_LEN:
                    break
                useful_metadata = {
                    "overexposure_lb": all_metadata["overexposure_lb"],
                    "crops": all_metadata["crops"],
                }
                if not useful_metadata["crops"]:
                    logging.warning(
                        f"CleanProfiledRGBCleanProfiledRGBImageCropsDataset.__init__: image {all_metadata} has no useful crops; not adding to dataset."
                    )
                else:
                    self._dataset.append(useful_metadata)
        logging.info(f"initialized {type(self).__name__} with {len(self)} images.")
        if len(self) == 0:
            raise ValueError("Dataset is empty")

    def __getitem__(self, i: int) -> RawDatasetOutput:
        metadata = self._dataset[i]
        crop: dict[str, str] = random.choice(metadata["crops"])
        try:
            gt = pt_helpers.fpath_to_tensor(crop["gt_linrec2020_fpath"]).float()
            rgbg_img = pt_helpers.fpath_to_tensor(
                crop["gt_bayer_fpath"]
            ).float()  # used to compute the overexposure mask
        except ValueError as e:
            logging.error(e)
            return self.__getitem__(random.randrange(len(self)))
        mask = self.get_mask(rgbg_img, metadata)
        if self.arbitrary_proc_method:
            gt = arbitrary_proc_fun.arbitrarily_process_images(
                gt,
                randseed=crop["gt_linrec2020_fpath"],
                method=self.arbitrary_proc_method,
            )
        try:
            x_crops, mask_crops = self.random_crops(gt, None, mask)
        except AssertionError as e:
            logging.info(crop)
            raise AssertionError(f"{self} {e} with {crop=}")
        except RuntimeError as e:
            logging.error(e)
            logging.error(f"{gt.shape=}, {rgbg_img.shape=}, {mask.shape=}")
            raise RuntimeError(f"{self} {e} with {crop=}")
        except TypeError:
            logging.warning(
                f"{crop} does not contain sufficient valid pixels; removing from dataset"
            )
            self._dataset[i]["crops"].remove(crop)
            if len(self._dataset[i]["crops"]) == 0:
                logging.warning(
                    f"{self._dataset[i]} does not contain anymore valid crops. Removing whole image from dataset."
                )
                self._dataset.remove(self._dataset[i])
            return self.__getitem__(i)
        return {"x_crops": x_crops, "mask_crops": mask_crops, "gain": 1.0}

    def __len__(self) -> int:
        return len(self._dataset)