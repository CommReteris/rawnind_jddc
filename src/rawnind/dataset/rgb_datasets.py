<<<<<<< HEAD
"""RGB dataset classes for profiled RGB image processing.

This module contains dataset classes specifically designed for handling profiled RGB
images, providing utilities for color space transformations and processing.
"""

import logging
import os
import sys
from typing import Optional

import torch

from .base_dataset import RawImageDataset


class ProfiledRGBProfiledRGBImageDataset(RawImageDataset):
    """Mixin for datasets that work with profiled RGB to profiled RGB transformations.

    This class provides a base for datasets where both input and target images
    are in profiled RGB color spaces, typically used for image enhancement
    or processing tasks that don't require color space conversion.
    """

    def __init__(self, num_crops: int, crop_size: int):
        super().__init__(num_crops=num_crops, crop_size=crop_size)
=======
"""
RGB-specific dataset classes for raw image processing.

This module contains dataset classes that handle profiled RGB images,
including clean-clean and clean-noisy RGB dataset handling.
"""

import logging
import random
from typing import Literal, Optional

import tqdm

from typing import Literal, Optional
from .base_dataset import RawImageDataset, CleanCleanImageDataset, CleanNoisyDataset, RawDatasetOutput, ALIGNMENT_MAX_LOSS, MASK_MEAN_MIN, TOY_DATASET_LEN
from ..dependencies import raw_processing as rawproc, pytorch_helpers as pt_helpers, load_yaml
from ..dependencies.arbitrary_processing import arbitrarily_process_images as arbitrary_proc_fun




class ProfiledRGBProfiledRGBImageDataset(RawImageDataset):
    """
    Dataset class for profiled RGB images.
    """

    def __init__(self, num_crops: int, crop_size: int):
        super().__init__(num_crops=num_crops, crop_size=crop_size)


class CleanProfiledRGBCleanProfiledRGBImageCropsDataset(
    CleanCleanImageDataset, ProfiledRGBProfiledRGBImageDataset
):
    """
    Dataloader for pre-cropped unpaired images generated by tools/crop_dataset.py w/ metadata from tools/prep_image_dataset_extraraw.py.
    """

    def __init__(
        self,
        content_fpaths: list[str],
        num_crops: int,
        crop_size: int,
        toy_dataset: bool = False,
        arbitrary_proc_method: bool = False,
    ):
        super().__init__(num_crops=num_crops, crop_size=crop_size)
        self.arbitrary_proc_method = arbitrary_proc_method
        self.num_crops = num_crops
        # self._dataset_xy_fpaths: list[tuple[str, str]] = []  # (gt_fpath, src_fpath)  # python 3.8 incompat
        self._dataset = []  # (gt_fpath, src_fpath)
        for content_fpath in content_fpaths:
            logging.info(
                f"CleanProfiledRGBCleanProfiledRGBImageCropsDataset.__init__: loading {content_fpath}"
            )
            ds_content = load_yaml(content_fpath, error_on_404=True)
            for all_metadata in tqdm.tqdm(ds_content):
                if toy_dataset and len(self._dataset) >= TOY_DATASET_LEN:
                    break
                useful_metadata = {
                    "overexposure_lb": all_metadata["overexposure_lb"],
                    "crops": all_metadata["crops"],
                }
                if not useful_metadata["crops"]:
                    logging.warning(
                        f"CleanProfiledRGBCleanProfiledRGBImageCropsDataset.__init__: image {all_metadata} has no useful crops; not adding to dataset."
                    )
                else:
                    self._dataset.append(useful_metadata)
        logging.info(f"initialized {type(self).__name__} with {len(self)} images.")
        if len(self) == 0:
            raise ValueError("Dataset is empty")

    def __getitem__(self, i: int) -> RawDatasetOutput:
        metadata = self._dataset[i]
        crop: dict[str, str] = random.choice(metadata["crops"])
        try:
            gt = pt_helpers.fpath_to_tensor(crop["gt_linrec2020_fpath"]).float()
            rgbg_img = pt_helpers.fpath_to_tensor(
                crop["gt_bayer_fpath"]
            ).float()  # used to compute the overexposure mask
        except ValueError as e:
            logging.error(e)
            return self.__getitem__(random.randrange(len(self)))
        mask = self.get_mask(rgbg_img, metadata)
        if self.arbitrary_proc_method:
            gt = arbitrary_proc_fun.arbitrarily_process_images(
                gt,
                randseed=crop["gt_linrec2020_fpath"],
                method=self.arbitrary_proc_method,
            )
        try:
            x_crops, mask_crops = self.random_crops(gt, None, mask)
        except AssertionError as e:
            logging.info(crop)
            raise AssertionError(f"{self} {e} with {crop=}")
        except RuntimeError as e:
            logging.error(e)
            logging.error(f"{gt.shape=}, {rgbg_img.shape=}, {mask.shape=}")
            raise RuntimeError(f"{self} {e} with {crop=}")
        except TypeError:
            logging.warning(
                f"{crop} does not contain sufficient valid pixels; removing from dataset"
            )
            self._dataset[i]["crops"].remove(crop)
            if len(self._dataset[i]["crops"]) == 0:
                logging.warning(
                    f"{self._dataset[i]} does not contain anymore valid crops. Removing whole image from dataset."
                )
                self._dataset.remove(self._dataset[i])
            return self.__getitem__(i)
        return {"x_crops": x_crops, "mask_crops": mask_crops, "gain": 1.0}

    def __len__(self) -> int:
        return len(self._dataset)


class CleanProfiledRGBNoisyProfiledRGBImageCropsDataset(
    CleanNoisyDataset, ProfiledRGBProfiledRGBImageDataset
):
    """
    Dataset of clean-noisy demosaiced images from rawNIND.

    Load from OpenEXR files.
    Returns aligned float crops, (highlight and anomaly) mask
    """

    def __init__(
        self,
        content_fpaths: list[str],
        num_crops: int,
        crop_size: int,
        test_reserve: list,
        bayer_only: bool,
        alignment_max_loss: float = ALIGNMENT_MAX_LOSS,
        mask_mean_min: float = MASK_MEAN_MIN,
        test: bool = False,
        toy_dataset: bool = False,
        data_pairing: Literal["x_y", "x_x", "y_y"] = "x_y",
        match_gain: bool = False,
        arbitrary_proc_method: bool = False,
        min_msssim_score: Optional[float] = 0.0,
        max_msssim_score: Optional[float] = 1.0,
    ):
        """
        content_fpaths points to a yaml file containing:
            - best_alignment
            - f_linrec2020_fpath
            - gt_linrec2020_fpath
            - mask_fpath
            - best_alignment_loss
            - mask_mean

        return_data
        """
        super().__init__(num_crops=num_crops, crop_size=crop_size)
        self.match_gain = match_gain
        self.arbitrary_proc_method = arbitrary_proc_method
        if self.arbitrary_proc_method:
            assert (
                self.match_gain
            ), f"{type(self).__name__}: arbitrary_proc_method requires match_gain"
        self.data_pairing = data_pairing
        # contents: list[dict] = utilities.load_yaml(content_fpath)
        for content_fpath in content_fpaths:
            contents = load_yaml(
                content_fpath, error_on_404=True
            )  # python38 incompat
            for image in contents:
                if toy_dataset and len(self._dataset) >= TOY_DATASET_LEN:
                    break

                # check that the image is (/not) reserved for testing
                if (
                    (not test and image["image_set"] in test_reserve)
                    or (test and image["image_set"] not in test_reserve)
                    or (  # check that there is a bayer version available if bayer_only is True
                        bayer_only and not image["is_bayer"]
                    )
                ):
                    # print(f'Image is (/not) reserved for testing: {image["image_set"]}')
                    continue
                try:
                    if (
                        min_msssim_score
                        and min_msssim_score > image["rgb_msssim_score"]
                    ):
                        continue
                    if (
                        max_msssim_score
                        and max_msssim_score != 1.0
                        and max_msssim_score < image["rgb_msssim_score"]
                    ):
                        print(
                            f"Skipping {image['f_fpath']} with {image['rgb_msssim_score']} > {max_msssim_score}"
                        )
                        continue
                except KeyError:
                    raise KeyError(
                        f"{image} does not contain msssim score (required with {min_msssim_score=})"
                    )

                if (
                    image["best_alignment_loss"] > alignment_max_loss
                    or image["mask_mean"] < mask_mean_min
                ):
                    logging.info(
                        f'{type(self).__name__}.__init__: rejected {image["f_fpath"]} (alignment or mask criteria)'
                    )
                    continue
                image["crops"] = sorted(
                    image["crops"], key=lambda d: d["coordinates"]
                )  # for testing
                if len(image["crops"]) > 0:
                    self._dataset.append(image)
                else:
                    logging.warning(
                        f"{type(self).__name__}.__init__: {image['f_fpath']} has no crops."
                    )
        logging.info(f"initialized {type(self).__name__} with {len(self)} images.")
        if len(self) == 0:
            raise ValueError("Dataset is empty")

    def __getitem__(
        self, i: int
    ):  # -> tuple[torch.Tensor, torch.Tensor, torch.BoolTensor]:
        """Returns a random crop triplet (ximage, yimage, mask).

        Args:
            i (int): Image index

        Returns:
            tuple[torch.Tensor, torch.Tensor, torch.BoolTensor]: random crop triplet
        """
        image = self._dataset[i]
        crop = random.choice(image["crops"])
        if self.data_pairing == "x_y":
            # load x, y, mask
            gt_img = pt_helpers.fpath_to_tensor(crop["gt_linrec2020_fpath"])
            noisy_img = pt_helpers.fpath_to_tensor(crop["f_linrec2020_fpath"])

            # align x, y
            gt_img, noisy_img = rawproc.shift_images(
                gt_img, noisy_img, image["best_alignment"]
            )
            whole_img_mask = pt_helpers.fpath_to_tensor(image["mask_fpath"])[
                :,
                crop["coordinates"][1] : crop["coordinates"][1] + gt_img.shape[1],
                crop["coordinates"][0] : crop["coordinates"][0] + gt_img.shape[2],
            ]
            whole_img_mask = whole_img_mask.expand(gt_img.shape)
        elif self.data_pairing == "x_x":
            gt_img = pt_helpers.fpath_to_tensor(crop["gt_linrec2020_fpath"])
            noisy_img = pt_helpers.fpath_to_tensor(crop["gt_linrec2020_fpath"])
            whole_img_mask = torch.ones_like(gt_img)
        elif self.data_pairing == "y_y":
            gt_img = pt_helpers.fpath_to_tensor(crop["f_linrec2020_fpath"])
            noisy_img = pt_helpers.fpath_to_tensor(crop["f_linrec2020_fpath"])
            whole_img_mask = torch.ones_like(gt_img)
        output = {}
        if self.match_gain:
            noisy_img *= image["rgb_gain"]
            output["gain"] = 1.0
        else:
            output["gain"] = image["rgb_gain"]
        if self.arbitrary_proc_method:
            # print(f"{self.__class__.__name__}.__getitem__ dbg: {crop['gt_linrec2020_fpath']=}, {self.arbitrary_proc_method=}")
            gt_img = arbitrary_proc_fun.arbitrarily_process_images(
                gt_img,
                randseed=crop["gt_linrec2020_fpath"],
                method=self.arbitrary_proc_method,
            )
            # print(f"{self.__class__.__name__}.__getitem__ dbg: {crop['f_linrec2020_fpath']=}, {self.arbitrary_proc_method=}")
            noisy_img = arbitrary_proc_fun.arbitrarily_process_images(
                noisy_img,
                randseed=crop["gt_linrec2020_fpath"],
                method=self.arbitrary_proc_method,
            )
        # crop x, y, mask
        try:
            x_crops, y_crops, mask_crops = self.random_crops(
                gt_img, noisy_img, whole_img_mask
            )
        except TypeError:
            logging.warning(
                f"{crop} does not contain sufficient valid pixels; removing from dataset"
            )
            self._dataset[i]["crops"].remove(crop)
            if len(self._dataset[i]["crops"]) == 0:
                logging.warning(
                    f"{self._dataset[i]} does not contain anymore valid crops. Removing whole image from dataset."
                )
                self._dataset.remove(self._dataset[i])
            return self.__getitem__(i)
        # mask_crops = mask_crops.unsqueeze(1).expand(x_crops.shape)
        output["x_crops"] = x_crops.float()
        output["y_crops"] = y_crops.float()
        output["mask_crops"] = mask_crops

        return output
        return {
            "x_crops": x_crops.float(),
            "y_crops": y_crops.float(),
            "mask_crops": mask_crops,
            "gain": image["rgb_gain"],
        }


class CleanProfiledRGBNoisyProfiledRGBImageCropsValidationDataset(
    CleanProfiledRGBNoisyProfiledRGBImageCropsDataset
):
    """
    Validation dataset for noisy profiled RGB to clean profiled RGB.
    """

    def __init__(
        self,
        content_fpaths: list[str],
        crop_size: int,
        test_reserve: list,
        bayer_only: bool,
        alignment_max_loss: float = ALIGNMENT_MAX_LOSS,
        mask_mean_min: float = MASK_MEAN_MIN,
        toy_dataset: bool = False,
        match_gain: bool = False,
        arbitrary_proc_method: bool = False,
        data_pairing: Literal["x_y", "x_x", "y_y"] = "x_y",
    ):
        super().__init__(
            content_fpaths=content_fpaths,
            num_crops=1,
            crop_size=crop_size,
            test_reserve=test_reserve,
            alignment_max_loss=alignment_max_loss,
            mask_mean_min=mask_mean_min,
            test=True,
            bayer_only=bayer_only,
            toy_dataset=toy_dataset,
            match_gain=match_gain,
            arbitrary_proc_method=arbitrary_proc_method,
            data_pairing=data_pairing,
        )

    def __getitem__(
        self, i: int
    ):  # -> tuple[torch.Tensor, torch.Tensor, torch.BoolTensor]:
        """Returns a center crop triplet (ximage, yimage, mask).

        Args:
            i (int): Image index

        Returns:
            tuple[torch.Tensor, torch.Tensor, torch.BoolTensor]: center crop triplet
        """
        image: dict = self._dataset[i]
        crop_n = len(image["crops"]) // 2
        crop = image["crops"][crop_n]
        # load x, y, mask
        if self.data_pairing == "x_y":
            gt_img = pt_helpers.fpath_to_tensor(crop["gt_linrec2020_fpath"])
            noisy_img = pt_helpers.fpath_to_tensor(crop["f_linrec2020_fpath"])

            # align x, y
            gt_img, noisy_img = rawproc.shift_images(
                gt_img, noisy_img, image["best_alignment"]
            )
            whole_img_mask = pt_helpers.fpath_to_tensor(image["mask_fpath"])[
                :,
                crop["coordinates"][1] : crop["coordinates"][1] + gt_img.shape[1],
                crop["coordinates"][0] : crop["coordinates"][0] + gt_img.shape[2],
            ]
            try:
                whole_img_mask = whole_img_mask.expand(gt_img.shape)
            except RuntimeError as e:
                logging.error(e)
                breakpoint()
        elif self.data_pairing == "x_x":
            gt_img = pt_helpers.fpath_to_tensor(crop["gt_linrec2020_fpath"])
            noisy_img = pt_helpers.fpath_to_tensor(crop["gt_linrec2020_fpath"])
            whole_img_mask = torch.ones_like(gt_img)
        elif self.data_pairing == "y_y":
            gt_img = pt_helpers.fpath_to_tensor(crop["f_linrec2020_fpath"])
            noisy_img = pt_helpers.fpath_to_tensor(crop["f_linrec2020_fpath"])
            whole_img_mask = torch.ones_like(gt_img)
        # crop x, y, mask, add alignment to mask
        if self.crop_size == 0:
            height, width = gt_img.shape[-2:]
            height = height - height % 256
            width = width - width % 256
            min_crop_size = 256
            x_crop = gt_img[..., :height, :width]
            noisy_img = y_crop = noisy_img[..., :height, :width]
            whole_img_mask = mask_crop = whole_img_mask[..., :height, :width]
        else:
            min_crop_size = self.crop_size
            x_crop, y_crop, mask_crop = self.center_crop(
                gt_img, noisy_img, whole_img_mask
            )
        if x_crop.shape[-1] < min_crop_size or x_crop.shape[-2] < min_crop_size:
            logging.warning(
                f"CleanProfiledRGBNoisyProfiledRGBImageCropsValidationDataset.__getitem__: not enough pixels in {crop['gt_linrec2020_fpath']}; deleting from dataset"
            )
            self._dataset[i]["crops"].remove(crop)
            return self.__getitem__(i)

        output = {
            "x_crops": x_crop.float(),
            "y_crops": y_crop.float(),
            "mask_crops": mask_crop,
            "gt_fpath": crop["gt_linrec2020_fpath"],
            "y_fpath": crop["f_linrec2020_fpath"],
        }
        if self.match_gain:
            output["y_crops"] *= image["rgb_gain"]
            output["gain"] = 1.0
        else:
            output["gain"] = image["rgb_gain"]
        if self.arbitrary_proc_method:
            output["x_crops"] = arbitrary_proc_fun.arbitrarily_process_images(
                output["x_crops"],
                randseed=crop["gt_linrec2020_fpath"],
                method=self.arbitrary_proc_method,
            )
            output["y_crops"] = arbitrary_proc_fun.arbitrarily_process_images(
                output["y_crops"],
                randseed=crop["gt_linrec2020_fpath"],
                method=self.arbitrary_proc_method,
            )
        return output


class CleanProfiledRGBNoisyProfiledRGBImageCropsTestDataloader(
    CleanProfiledRGBNoisyProfiledRGBImageCropsDataset
):
    """
    Test dataloader for clean (profiled RGB) - noisy (profiled RGB) images from rawNIND.
    """

    def __init__(
        self,
        content_fpaths: list[str],
        crop_size: int,
        test_reserve: list,
        bayer_only: bool,
        alignment_max_loss: float = ALIGNMENT_MAX_LOSS,
        mask_mean_min: float = MASK_MEAN_MIN,
        toy_dataset: bool = False,
        match_gain: bool = False,
        arbitrary_proc_method: bool = False,
        min_msssim_score: Optional[float] = 0.0,
        max_msssim_score: Optional[float] = 1.0,
    ):
        super().__init__(
            content_fpaths=content_fpaths,
            num_crops=1,
            crop_size=crop_size,
            test_reserve=test_reserve,
            alignment_max_loss=alignment_max_loss,
            mask_mean_min=mask_mean_min,
            test=True,
            bayer_only=bayer_only,
            toy_dataset=toy_dataset,
            match_gain=match_gain,
            arbitrary_proc_method=arbitrary_proc_method,
            min_msssim_score=min_msssim_score,
            max_msssim_score=max_msssim_score,
        )

    def get_images(self):
        """
        Yield test images one crop at a time. Replaces __getitem__ s.t. the image is not re-loaded many times.
        """
        for image in self._dataset:
            for crop in image["crops"]:
                gt_img = pt_helpers.fpath_to_tensor(crop["gt_linrec2020_fpath"]).float()
                noisy_img = pt_helpers.fpath_to_tensor(
                    crop["f_linrec2020_fpath"]
                ).float()

                gt_img, noisy_img = rawproc.shift_images(
                    gt_img, noisy_img, image["best_alignment"]
                )
                whole_img_mask = pt_helpers.fpath_to_tensor(image["mask_fpath"])[
                    :,
                    crop["coordinates"][1] : crop["coordinates"][1] + gt_img.shape[1],
                    crop["coordinates"][0] : crop["coordinates"][0] + gt_img.shape[2],
                ].expand(gt_img.shape)
                height, width = gt_img.shape[-2:]
                if self.match_gain:
                    noisy_img *= image["rgb_gain"]
                    out_gain = 1.0
                else:
                    out_gain = image["rgb_gain"]

                if self.arbitrary_proc_method:
                    gt_img = arbitrary_proc_fun.arbitrarily_process_images(
                        gt_img,
                        randseed=crop["gt_linrec2020_fpath"],
                        method=self.arbitrary_proc_method,
                    )
                    noisy_img = arbitrary_proc_fun.arbitrarily_process_images(
                        noisy_img,
                        randseed=crop["gt_linrec2020_fpath"],
                        method=self.arbitrary_proc_method,
                    )
                if self.crop_size == 0:
                    height = height - height % 256
                    width = width - width % 256
                    if height == 0 or width == 0:
                        continue
                    yield (
                        {
                            "x_crops": gt_img[
                                ...,
                                :height,
                                :width,
                            ].unsqueeze(0),
                            "y_crops": noisy_img[
                                ...,
                                :height,
                                :width,
                            ].unsqueeze(0),
                            "mask_crops": whole_img_mask[
                                ...,
                                :height,
                                :width,
                            ].unsqueeze(0),
                            "gt_fpath": crop["gt_linrec2020_fpath"],
                            "y_fpath": crop["f_linrec2020_fpath"],
                            "gain": torch.tensor(out_gain),
                        }
                    )
                else:
                    x = y = 0
                    while y < height:
                        while x < width:
                            if (
                                y + self.crop_size <= height
                                and x + self.crop_size <= width
                            ):
                                yield (
                                    {
                                        "x_crops": gt_img[
                                            ...,
                                            y : y + self.crop_size,
                                            x : x + self.crop_size,
                                        ].unsqueeze(0),
                                        "y_crops": noisy_img[
                                            ...,
                                            y : y + self.crop_size,
                                            x : x + self.crop_size,
                                        ].unsqueeze(0),
                                        "mask_crops": whole_img_mask[
                                            ...,
                                            y : y + self.crop_size,
                                            x : x + self.crop_size,
                                        ].unsqueeze(0),
                                        "gt_fpath": crop["gt_linrec2020_fpath"],
                                        "y_fpath": crop["f_linrec2020_fpath"],
                                        "gain": torch.tensor(out_gain),
                                    }
                                )
                            x += self.crop_size
                        x = 0
                        y += self.crop_size
>>>>>>> 9d829208844a9450effb8f515b5521749b6aed0c
