"""Bayer pattern dataset classes for raw image processing.

This module contains dataset classes specifically designed for handling Bayer pattern
<<<<<<< HEAD
images, including color space conversions and demosaicing operations.
"""

import logging
import os
import sys
from typing import Optional

import torch

from .base_dataset import RawImageDataset
# Import raw processing (will be moved to dependencies later)
from ..libs import raw


class ProfiledRGBBayerImageDataset(RawImageDataset):
    """Mixin for datasets that process Profiled RGB to Bayer transformations.

    Provides utility methods for converting camera RGB images to standard color
    profiles, which is essential for training models that work with Bayer patterns
    while maintaining color accuracy.
=======
images, including color space conversions, Bayer-specific cropping logic and demosaicing operations.
"""

import logging
from typing import Optional, Literal

import torch
import random
from tqdm import tqdm

from rawnind.dependencies import raw_processing as rawproc, load_yaml
import rawnind.dependencies.pytorch_helpers as pt_helpers

from .base_dataset import RawImageDataset, CleanCleanImageDataset, CleanNoisyDataset, RawDatasetOutput


class ProfiledRGBBayerImageDataset(RawImageDataset):
    """
    Dataset class for Bayer images with profiled RGB conversion.
>>>>>>> 9d829208844a9450effb8f515b5521749b6aed0c
    """

    def __init__(self, num_crops: int, crop_size: int):
        super().__init__(num_crops=num_crops, crop_size=crop_size)

    @staticmethod
    def camRGB_to_profiledRGB_img(
            camRGB_img: torch.Tensor,
            metadata: dict,
            output_color_profile="lin_rec2020",
    ) -> torch.Tensor:
<<<<<<< HEAD
        return raw.camRGB_to_profiledRGB_img(camRGB_img, metadata, output_color_profile)
=======
        return rawproc.camRGB_to_profiledRGB_img(camRGB_img, metadata, output_color_profile)


class CleanProfiledRGBCleanBayerImageCropsDataset(
    CleanCleanImageDataset, ProfiledRGBBayerImageDataset
):
    """
    Dataloader for pre-cropped unpaired images generated by tools/crop_dataset.py w/ metadata from
    tools/prep_image_dataset_extraraw.py.
    """

    def __init__(
            self,
            content_fpaths: list[str],
            num_crops: int,
            crop_size: int,
            toy_dataset: bool = False,
    ):
        super().__init__(num_crops=num_crops, crop_size=crop_size)
        self.num_crops = num_crops
        # self._dataset_xy_fpaths: list[tuple[str, str]] = []  # (gt_fpath, src_fpath)  # python 3.8 incompat
        self._dataset = []  # (gt_fpath, src_fpath)
        for content_fpath in content_fpaths:
            logging.info(
                f"CleanProfiledRGBCleanBayerImageCropsDataset.__init__: loading {content_fpath}"
            )
            ds_content = load_yaml(content_fpath, error_on_404=True)
            for all_metadata in tqdm.tqdm(ds_content):
                if toy_dataset and len(self._dataset) >= TOY_DATASET_LEN:
                    break
                useful_metadata = {
                    "overexposure_lb": all_metadata["overexposure_lb"],
                    "rgb_xyz_matrix" : torch.tensor(all_metadata["rgb_xyz_matrix"]),
                    "crops"          : all_metadata["crops"],
                }
                if not useful_metadata["crops"]:
                    logging.warning(
                        f"CleanProfiledRGBCleanBayerImageCropsDataset.__init__: image {all_metadata} has no useful "
                        f"crops; not adding to dataset."
                    )
                else:
                    self._dataset.append(useful_metadata)
        logging.info(f"initialized {type(self).__name__} with {len(self)} images.")
        if len(self) == 0:
            raise ValueError("Dataset is empty")

    def __getitem__(self, i: int) -> RawDatasetOutput:
        metadata = self._dataset[i]
        crop: dict[str, str] = random.choice(metadata["crops"])
        try:
            gt = pt_helpers.fpath_to_tensor(crop["gt_linrec2020_fpath"]).float()
            rgbg_img = pt_helpers.fpath_to_tensor(crop["gt_bayer_fpath"]).float()
        except ValueError as e:
            logging.error(e)
            return self.__getitem__(random.randrange(len(self)))
        mask = self.get_mask(rgbg_img, metadata)
        try:
            x_crops, y_crops, mask_crops = self.random_crops(gt, rgbg_img, mask)
        except AssertionError as e:
            logging.info(crop)
            raise AssertionError(f"{self} {e} with {crop=}")
        except RuntimeError as e:
            logging.error(e)
            logging.error(f"{gt.shape=}, {rgbg_img.shape=}, {mask.shape=}")
            raise RuntimeError(f"{self} {e} with {crop=}")
        except TypeError:
            logging.warning(
                f"{crop} does not contain sufficient valid pixels; removing from dataset"
            )
            self._dataset[i]["crops"].remove(crop)
            if len(self._dataset[i]["crops"]) == 0:
                logging.warning(
                    f"{self._dataset[i]} does not contain anymore valid crops. Removing whole image from dataset."
                )
                self._dataset.remove(self._dataset[i])
            return self.__getitem__(i)
        return {
            "x_crops"       : x_crops,
            "y_crops"       : y_crops,
            "mask_crops"    : mask_crops,
            "rgb_xyz_matrix": metadata["rgb_xyz_matrix"],
            "gain"          : 1.0,
        }

    def __len__(self) -> int:
        return len(self._dataset)


TOY_DATASET_LEN = 100
ALIGNMENT_MAX_LOSS = 0.05

MASK_MEAN_MIN = 0.01


class CleanProfiledRGBNoisyBayerImageCropsDataset(
    CleanNoisyDataset, ProfiledRGBBayerImageDataset
):
    """
    Dataset of clean-noisy raw images from rawNIND.

    Load from raw files using rawpy.
    Returns float crops, (highlight and anomaly) mask, metadata

    Alignment and masks are pre-computed.
    Output metadata contains color_matrix.
    """

    def __init__(
            self,
            content_fpaths: list[str],
            num_crops: int,
            crop_size: int,
            test_reserve: list,
            bayer_only: bool = True,
            alignment_max_loss: float = ALIGNMENT_MAX_LOSS,
            mask_mean_min: float = MASK_MEAN_MIN,
            test: bool = False,
            toy_dataset: bool = False,
            data_pairing: Literal["x_y", "x_x", "y_y"] = "x_y",  # x_y, x_x, y_y
            match_gain: bool = False,
            min_msssim_score: Optional[float] = 0.0,
            max_msssim_score: Optional[float] = 1.0,
    ):
        """
        content_fpaths points to a yaml file containing:
            - best_alignment
            - f_bayer_fpath
            - gt_linrec2020_fpath
            - mask_fpath
            - best_alignment_loss
            - mask_mean

        return_data
        """
        super().__init__(num_crops=num_crops, crop_size=crop_size)
        self.match_gain = match_gain
        assert bayer_only
        # contents: list[dict] = utilities.load_yaml(content_fpath)
        for content_fpath in content_fpaths:
            contents = load_yaml(
                content_fpath, error_on_404=True
            )  # python 3.8 incompat
            for image in contents:
                if toy_dataset and len(self._dataset) >= TOY_DATASET_LEN:
                    break
                if not image["is_bayer"]:
                    continue

                # check that the image is (/not) reserved for testing
                if (not test and image["image_set"] in test_reserve) or (
                        test and image["image_set"] not in test_reserve
                ):
                    continue
                try:
                    if (
                            min_msssim_score
                            and min_msssim_score > image["rgb_msssim_score"]
                    ):
                        print(
                            f"Skipping {image['f_fpath']} with {image['rgb_msssim_score']} < {min_msssim_score}"
                        )
                        continue
                    if (
                            max_msssim_score
                            and max_msssim_score != 1.0
                            and max_msssim_score < image["rgb_msssim_score"]
                    ):
                        print(
                            f"Skipping {image['f_fpath']} with {image['rgb_msssim_score']} > {max_msssim_score}"
                        )
                        continue
                except KeyError:
                    raise KeyError(
                        f"{image} does not contain msssim score (required with {min_msssim_score=})"
                    )
                if (
                        image["best_alignment_loss"] > alignment_max_loss
                        or image["mask_mean"] < mask_mean_min
                ):
                    logging.info(
                        f'{type(self).__name__}.__init__: rejected {image["f_fpath"]} (alignment or mask criteria)'
                    )
                    continue
                image["crops"] = sorted(
                    image["crops"], key=lambda d: d["coordinates"]
                )  # for testing
                if len(image["crops"]) > 0:
                    self._dataset.append(image)
                else:
                    logging.warning(
                        f'{type(self).__name__}.__init__: {image["f_fpath"]} has no crops.'
                    )
        logging.info(f"initialized {type(self).__name__} with {len(self)} images.")
        assert (
                len(self) > 0
        ), f"{type(self).__name__} has no images. {content_fpaths=}, {test_reserve=}"
        self.data_pairing = data_pairing

    def __getitem__(self, i: int) -> RawDatasetOutput:
        image: dict = self._dataset[i]
        # load x, y, mask
        crop = random.choice(image["crops"])
        if self.data_pairing == "x_y":
            gt_img = pt_helpers.fpath_to_tensor(crop["gt_linrec2020_fpath"])
            noisy_img = pt_helpers.fpath_to_tensor(crop["f_bayer_fpath"])
            # gt_img = self.crop_rgb_to_bayer(gt_img, metadata)

            # align x, y

            gt_img, noisy_img = rawproc.shift_images(
                gt_img, noisy_img, image["best_alignment"]
            )

            whole_img_mask = pt_helpers.fpath_to_tensor(image["mask_fpath"])[
                :,
                crop["coordinates"][1]: crop["coordinates"][1] + gt_img.shape[1],
                crop["coordinates"][0]: crop["coordinates"][0] + gt_img.shape[2],
            ]
            whole_img_mask = whole_img_mask.expand(gt_img.shape)
        elif self.data_pairing == "x_x":
            gt_img = pt_helpers.fpath_to_tensor(crop["gt_linrec2020_fpath"])
            noisy_img = pt_helpers.fpath_to_tensor(crop["gt_bayer_fpath"])
            whole_img_mask = torch.ones_like(gt_img)
        elif self.data_pairing == "y_y":
            gt_img = pt_helpers.fpath_to_tensor(crop["f_linrec2020_fpath"])
            noisy_img = pt_helpers.fpath_to_tensor(crop["f_bayer_fpath"])
            whole_img_mask = torch.ones_like(gt_img)
        else:
            raise ValueError(f"return_data={self.data_pairing} not supported")

        # crop x, y, mask, add alignment to mask
        try:
            x_crops, y_crops, mask_crops = self.random_crops(
                gt_img, noisy_img, whole_img_mask
            )
        except AssertionError as e:
            logging.info(crop)
            raise AssertionError(f"{self} {e} with {crop=}")
        except RuntimeError as e:
            logging.error(e)
            logging.error(f"{gt_img.shape=}, {noisy_img.shape=}, {whole_img_mask.shape=}")
            raise RuntimeError(f"{self} {e} with {crop=}")
        except TypeError:
            logging.warning(
                f"{crop} does not contain sufficient valid pixels; removing from dataset"
            )
            self._dataset[i]["crops"].remove(crop)
            if len(self._dataset[i]["crops"]) == 0:
                logging.warning(
                    f"{self._dataset[i]} does not contain anymore valid crops. Removing whole image from dataset."
                )
                self._dataset.remove(self._dataset[i])
            return self.__getitem__(i)
        # hardcoded_rgbm = torch.tensor(
        #     [
        #         [0.7034, -0.0804, -0.1014],
        #         [-0.4420, 1.2564, 0.2058],
        #         [-0.0851, 0.1994, 0.5758],
        #         [0.0000, 0.0000, 0.0000],
        #     ]
        # )
        output = {
            "x_crops"       : x_crops,
            "y_crops"       : y_crops,
            "mask_crops"    : mask_crops,
            # "rgb_xyz_matrix": hardcoded_rgbm  # TODO RM DBG
            "rgb_xyz_matrix": torch.tensor(image["rgb_xyz_matrix"]),
        }
        if self.match_gain:
            output["y_crops"] *= image["raw_gain"]
            output["gain"] = 1.0
        else:
            output["gain"] = image["raw_gain"]
        return output


class CleanProfiledRGBNoisyBayerImageCropsValidationDataset(
    CleanProfiledRGBNoisyBayerImageCropsDataset
):
    """
    Validation dataset for noisy Bayer to clean profiled RGB.
    """

    def __init__(
            self,
            content_fpaths: list[str],
            crop_size: int,
            test_reserve: list,
            bayer_only: bool,
            toy_dataset: bool = False,
            match_gain: bool = False,
            data_pairing: Literal["x_y", "x_x", "y_y"] = "x_y",
    ):
        super().__init__(
            content_fpaths=content_fpaths,
            num_crops=1,
            crop_size=crop_size,
            test_reserve=test_reserve,
            bayer_only=bayer_only,
            toy_dataset=toy_dataset,
            match_gain=match_gain,
            data_pairing=data_pairing,
        )


class CleanProfiledRGBNoisyBayerImageCropsTestDataloader(
    CleanProfiledRGBNoisyBayerImageCropsDataset
):
    """
    Test dataloader for clean (profiled RGB) - noisy (Bayer) images from rawNIND.
    """

    def __init__(
            self,
            content_fpaths: list[str],
            crop_size: int,
            test_reserve: list,
            bayer_only: bool,
            toy_dataset: bool = False,
            match_gain: bool = False,
            min_msssim_score: Optional[float] = 0.0,
            max_msssim_score: Optional[float] = 1.0,
    ):
        super().__init__(
            content_fpaths=content_fpaths,
            num_crops=1,
            crop_size=crop_size,
            test_reserve=test_reserve,
            bayer_only=bayer_only,
            toy_dataset=toy_dataset,
            match_gain=match_gain,
            min_msssim_score=min_msssim_score,
            max_msssim_score=max_msssim_score,
        )

    def get_images(self):
        """
        Yield test images one crop at a time. Replaces __getitem__ s.t. the image is not re-loaded many times.
        """
        for image in self._dataset:
            rgb_xyz_matrix = torch.tensor(image["rgb_xyz_matrix"])
            for crop in image["crops"]:
                gt_img = pt_helpers.fpath_to_tensor(crop["gt_linrec2020_fpath"]).float()
                noisy_img = pt_helpers.fpath_to_tensor(crop["f_bayer_fpath"]).float()
                # gt_img = self.crop_rgb_to_bayer(gt_img, metadata)

                gt_img, noisy_img = rawproc.shift_images(
                    gt_img, noisy_img, image["best_alignment"]
                )
                whole_img_mask = pt_helpers.fpath_to_tensor(image["mask_fpath"])[
                    :,
                    crop["coordinates"][1]: crop["coordinates"][1] + gt_img.shape[1],
                    crop["coordinates"][0]: crop["coordinates"][0] + gt_img.shape[2],
                ].expand(gt_img.shape)

                height, width = gt_img.shape[-2:]
                if self.match_gain:
                    noisy_img *= image["raw_gain"]
                    out_gain = 1.0
                else:
                    out_gain = image["raw_gain"]
                if self.crop_size == 0:
                    height = height - height % 256
                    width = width - width % 256
                    min_crop_size = 256
                    x_crop = gt_img[..., :height, :width]
                    y_crop = noisy_img[..., : height // 2, : width // 2]
                    mask_crop = whole_img_mask[..., :height, :width]
                    yield {
                        "x_crops"       : x_crop.unsqueeze(0),
                        "y_crops"       : y_crop.unsqueeze(0),
                        "mask_crops"    : mask_crop.unsqueeze(0),
                        "rgb_xyz_matrix": rgb_xyz_matrix.unsqueeze(0),
                        "gt_fpath"      : crop["gt_linrec2020_fpath"],
                        "y_fpath"       : crop["f_bayer_fpath"],
                        "gain"          : torch.tensor(out_gain),
                    }
                else:
                    min_crop_size = self.crop_size
                    y = x = 0
                    while y < height:
                        while x < width:
                            if (
                                    y + self.crop_size <= height
                                    and x + self.crop_size <= width
                            ):
                                yield {
                                    "x_crops"       : gt_img[
                                        ...,
                                        y: y + self.crop_size,
                                        x: x + self.crop_size,
                                    ].unsqueeze(0),
                                    "y_crops"       : noisy_img[
                                        ...,
                                        y // 2: y // 2 + self.crop_size // 2,
                                        x // 2: x // 2 + self.crop_size // 2,
                                    ].unsqueeze(0),
                                    "mask_crops"    : whole_img_mask[
                                        ...,
                                        y: y + self.crop_size,
                                        x: x + self.crop_size,
                                    ].unsqueeze(0),
                                    "rgb_xyz_matrix": rgb_xyz_matrix.unsqueeze(0),
                                    "gt_fpath"      : crop["gt_linrec2020_fpath"],
                                    "y_fpath"       : crop["f_bayer_fpath"],
                                    "gain"          : torch.tensor(out_gain),
                                }
                            x += self.crop_size
                        x = 0
                        y += self.crop_size
>>>>>>> 9d829208844a9450effb8f515b5521749b6aed0c
